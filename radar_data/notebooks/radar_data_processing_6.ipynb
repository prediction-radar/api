{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nRaN7EsWE-Na"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from matplotlib import cm\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "root_dir = os.path.dirname(os.getcwd()) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the .npy files into a list\n",
    "npy_files = sorted(glob(root_dir + 'data/npy_files/*.npy'))\n",
    "\n",
    "# Load the first .npy file to get the unique latitudes and longitudes of this data set\n",
    "example_grid = np.load(npy_files[0])\n",
    "unique_latitudes = example_grid.shape[1]\n",
    "unique_longitudes = example_grid.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in enumerate(npy_files):\n",
    "    array = np.load(i[1])\n",
    "    \n",
    "    array[array < 20] = 0\n",
    "\n",
    "    np.save(i[1], array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume npy_files and unique_latitudes, unique_longitudes are already defined\n",
    "sequence_length = 15 # Number of .npy files to look back on\n",
    "prediction_horizon = 15 # Number of .npy files to predict\n",
    "height, width = unique_latitudes, unique_longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split a single grid into 250x250 squares\n",
    "def split_single_grid(file, square_size=250, height=3500, width=7000):\n",
    "    grid = np.load(file).reshape(height, width, 1)\n",
    "    squares = [\n",
    "        grid[i:i+square_size, j:j+square_size]\n",
    "        for i in range(0, height, square_size)\n",
    "        for j in range(0, width, square_size)\n",
    "    ]\n",
    "    return np.array(squares)\n",
    "\n",
    "# Function to split all grids sequentially (no parallelization)\n",
    "def split_all_grids_sequential(npy_files, square_size=250, height=3500, width=7000):\n",
    "    num_squares_per_grid = (height // square_size) * (width // square_size)\n",
    "    num_files = len(npy_files)\n",
    "\n",
    "    # Preallocate space for all the grids that will be split into squares\n",
    "    all_squares = np.empty((num_files, num_squares_per_grid, square_size, square_size, 1), dtype=np.float32)\n",
    "\n",
    "    # Sequentially process each file and store the result\n",
    "    for idx, file in enumerate(npy_files):\n",
    "        squares = split_single_grid(file, square_size, height, width)\n",
    "        all_squares[idx] = squares\n",
    "\n",
    "    return all_squares\n",
    "\n",
    "# Assume npy_files, sequence_length, and prediction_horizon are already defined\n",
    "square_size = 250\n",
    "height, width = 3500, 7000  # Original image size\n",
    "num_squares = 392\n",
    "\n",
    "# Pre-split all grids into squares sequentially\n",
    "all_squares = split_all_grids_sequential(npy_files, square_size=square_size, height=height, width=width)\n",
    "\n",
    "# Now, treat each square as an independent sample\n",
    "num_files = len(npy_files)\n",
    "num_samples = (num_files - sequence_length - prediction_horizon + 1) * num_squares\n",
    "\n",
    "# Pre-allocate arrays for input (X) and output (y) sequences\n",
    "X = np.empty((num_samples, sequence_length, square_size, square_size, 1), dtype=np.float32)\n",
    "y = np.empty((num_samples, prediction_horizon, square_size, square_size, 1), dtype=np.float32)\n",
    "\n",
    "# Populate X and y arrays using pre-split squares\n",
    "sample_idx = 0\n",
    "for i in range(num_files - sequence_length - prediction_horizon + 1):\n",
    "    for j in range(num_squares):\n",
    "        # For each sample, take the sequence for that square over time\n",
    "        x_sample = all_squares[i:i+sequence_length, j]\n",
    "        X[sample_idx] = x_sample\n",
    "\n",
    "        y_sample = all_squares[i+sequence_length:i+sequence_length+prediction_horizon, j]\n",
    "        y[sample_idx] = y_sample\n",
    "\n",
    "        sample_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(X, y):\n",
    "    \"\"\"\n",
    "    Removes duplicates from X and y where every pixel in the image sequences is the same.\n",
    "    Only unique (X, y) pairs are retained.\n",
    "    \n",
    "    Args:\n",
    "    - X: numpy array of shape (num_samples, sequence_length, image_width, image_height, 1)\n",
    "    - y: numpy array of shape (num_samples, prediction_horizon, image_width, image_height, 1)\n",
    "    \n",
    "    Returns:\n",
    "    - X_unique: numpy array of unique input sequences\n",
    "    - y_unique: numpy array of corresponding unique output sequences\n",
    "    \"\"\"\n",
    "    unique_indices = []\n",
    "    num_samples = X.shape[0]\n",
    "    \n",
    "    # Track whether we've already seen a duplicate\n",
    "    seen = np.zeros(num_samples, dtype=bool)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        if seen[i]:\n",
    "            continue  # Skip if this sample was already identified as a duplicate\n",
    "        \n",
    "        # Mark the current sample as part of the unique set\n",
    "        unique_indices.append(i)\n",
    "        \n",
    "        # Check for duplicates in the rest of the dataset\n",
    "        for j in range(i + 1, num_samples):\n",
    "            if seen[j]:\n",
    "                continue  # Skip already marked duplicates\n",
    "            \n",
    "            # Check if both X and y sequences are identical\n",
    "            if np.array_equal(X[i], X[j]) and np.array_equal(y[i], y[j]):\n",
    "                seen[j] = True  # Mark this as a duplicate\n",
    "    \n",
    "    # Select only the unique indices for X and y\n",
    "    X_unique = X[unique_indices]\n",
    "    y_unique = y[unique_indices]\n",
    "    \n",
    "    return X_unique, y_unique\n",
    "\n",
    "X_unique, y_unique = remove_duplicates(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# First split: train and temp (which will later be split into validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_unique, y_unique, test_size=(1 - train_ratio)\n",
    ")\n",
    "\n",
    "# Second split: validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=(test_ratio / (test_ratio + val_ratio))\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the colors for the radar map, introducing white for values between 0 and 15\n",
    "colors = [\n",
    "    (0, 0, 0),         # White for values 0-15 (no precipitation or very light)\n",
    "    (0, 0.7, 0),       # Green (light precipitation)\n",
    "    (1, 1, 0),         # Yellow (moderate precipitation)\n",
    "    (1, 0.65, 0),      # Orange (heavy precipitation)\n",
    "    (1, 0, 0),         # Red (very heavy precipitation)\n",
    "    (0.6, 0, 0.6)      # Purple (extreme precipitation)\n",
    "]\n",
    "\n",
    "# Define the breakpoints for the color transition, where 0-15 is white\n",
    "breakpoints = [0.0, 15/80.0, 40/80.0, 60/80.0, 70/80.0, 1.0]\n",
    "\n",
    "# Create the custom colormap\n",
    "radar_cmap = LinearSegmentedColormap.from_list('radar', colors, N=256)\n",
    "\n",
    "# Normalize the data range from 0 to 80\n",
    "norm = Normalize(vmin=0, vmax=80)\n",
    "\n",
    "# Construct a figure to visualize the images\n",
    "x_fig, x_axes = plt.subplots(3, 5, figsize=(20, 14))\n",
    "y_fig, y_axes = plt.subplots(3, 5, figsize=(20, 14))\n",
    "\n",
    "# Randomly choose a data example to visualize\n",
    "data_choice = np.random.choice(range(len(X_train)), size=1)[0]\n",
    "lastdata = None  # Initialize lastdata to None before looping\n",
    "\n",
    "# Plot each of the sequential images for one random data example\n",
    "for idx, ax in enumerate(x_axes.flat):\n",
    "    x_thisdata = X_train[data_choice][idx]\n",
    "\n",
    "    # Compare the current data to the last one if lastdata is not None\n",
    "    if lastdata is not None and np.array_equal(x_thisdata, lastdata):\n",
    "        print(f\"Frame x - {idx + 1} is the same as the previous frame.\")\n",
    "\n",
    "    # Display the image with the radar colormap and normalization\n",
    "    im = ax.imshow(np.squeeze(x_thisdata), cmap=radar_cmap, norm=norm)\n",
    "    \n",
    "    # Add title and remove axis\n",
    "    ax.set_title(f\"Frame X - {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Update lastdata\n",
    "    lastdata = x_thisdata\n",
    "\n",
    "# Print information and display the figure\n",
    "print(f\"Displaying frames for example {data_choice}.\")\n",
    "\n",
    "for idx, ax in enumerate(y_axes.flat):\n",
    "    y_thisdata = y_train[data_choice][idx]\n",
    "\n",
    "    # Compare the current data to the last one if lastdata is not None\n",
    "    if lastdata is not None and np.array_equal(y_thisdata, lastdata):\n",
    "        print(f\"Frame y - {idx + 1} is the same as the previous frame.\")\n",
    "\n",
    "    # Display the image with the radar colormap and normalization\n",
    "    im = ax.imshow(np.squeeze(y_thisdata), cmap=radar_cmap, norm=norm)\n",
    "    \n",
    "    # Add title and remove axis\n",
    "    ax.set_title(f\"Frame y - {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Update lastdata\n",
    "    lastdata = y_thisdata\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import ConvLSTM2D, Conv3D, BatchNormalization, Input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "import io\n",
    "import imageio\n",
    "from IPython.display import Image, display\n",
    "from ipywidgets import widgets, Layout, HBox\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import subprocess\n",
    "\n",
    "# channels = 1  # Reflectivity is your feature, so 1 channel\n",
    "\n",
    "# # Define the model using an Input layer for the input shape\n",
    "# model = Sequential()\n",
    "\n",
    "# # Add Input Layer\n",
    "# model.add(Input(shape=(sequence_length, square_size, square_size, channels))) \n",
    "\n",
    "# # First ConvLSTM2D layer with return_sequences=True\n",
    "# model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', return_sequences=True))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# # Second ConvLSTM2D layer with return_sequences=True to return all frames\n",
    "# model.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same', return_sequences=True))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# # Replace Conv3D with Conv2D to predict the next frame(s)\n",
    "# model.add(Conv3D(filters=1, kernel_size=(3, 3, 3), activation='linear', padding='same'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# # Print model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"model6_3.keras\"\n",
    "model = load_model(root_dir + f\"model/{model_name}\")\n",
    "# Create an Adam optimizer with a custom learning rate\n",
    "optimizer = Adam(learning_rate=0.0001)  # Set the learning rate here\n",
    "\n",
    "# Compile the model with the optimizer\n",
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    features_mem = 0  # Initialize memory for features\n",
    "    float_bytes = 4.0  # Float32 uses 4 bytes\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        # Use layer.output.shape to get the output shape instead of output_shape\n",
    "        out_shape = layer.output.shape\n",
    "        \n",
    "        # Remove the batch size dimension (out_shape[0]) and None (which represents the batch dimension)\n",
    "        out_shape = [dim for dim in out_shape if dim is not None]\n",
    "        \n",
    "        # Multiply all output shape dimensions to calculate the number of elements per layer\n",
    "        single_layer_mem = 1\n",
    "        for s in out_shape:\n",
    "            single_layer_mem *= s\n",
    "            \n",
    "        # Convert to memory (in bytes and MB)\n",
    "        single_layer_mem_float = single_layer_mem * float_bytes  # Multiply by 4 bytes (float32)\n",
    "        single_layer_mem_MB = single_layer_mem_float / (1024 ** 2)  # Convert to MB\n",
    "        \n",
    "        print(f\"Memory for layer {layer.name} with output shape {out_shape} is: {single_layer_mem_MB:.2f} MB\")\n",
    "        \n",
    "        features_mem += single_layer_mem_MB  # Accumulate total feature memory\n",
    "    \n",
    "    # Calculate Parameter memory\n",
    "    trainable_wts = np.sum([K.count_params(p) for p in model.trainable_weights])\n",
    "    non_trainable_wts = np.sum([K.count_params(p) for p in model.non_trainable_weights])\n",
    "    parameter_mem_MB = ((trainable_wts + non_trainable_wts) * float_bytes) / (1024 ** 2)\n",
    "    \n",
    "    print(\"_________________________________________\")\n",
    "    print(f\"Memory for features in MB is: {features_mem * batch_size:.2f} MB\")\n",
    "    print(f\"Memory for parameters in MB is: {parameter_mem_MB:.2f} MB\")\n",
    "\n",
    "    total_memory_MB = (batch_size * features_mem) + parameter_mem_MB\n",
    "    total_memory_GB = total_memory_MB / 1024  # Convert to GB\n",
    "    \n",
    "    return total_memory_GB\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "mem_for_my_model = get_model_memory_usage(1, model)\n",
    "\n",
    "print(\"_________________________________________\")\n",
    "print(\"Minimum memory required to work with this model is: %.2f\" %mem_for_my_model, \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = ModelCheckpoint(root_dir + f\"model/{model_name}\", save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "          batch_size=2, \n",
    "          epochs=200, \n",
    "          callbacks=[cp, early_stopping],\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the model saved by ModelCheckpoint\n",
    "model_path = root_dir + f\"model/{model_name}\"\n",
    "\n",
    "# Extract last val_accuracy/val_loss from the training history\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Commit and push the model to GitHub\n",
    "commit_message = f\"Add trained model with val_loss: {val_loss}\"\n",
    "\n",
    "commands = [\n",
    "    \"git config --global user.email 'tw@trevorwiebe.com'\",\n",
    "    \"git config --global user.name 'Trevor Wiebe'\",\n",
    "    f\"git add {model_path}\",  # Assuming `model_path` is where your model is saved\n",
    "    f'git commit -m \"{commit_message}\"',\n",
    "    \"git push\"\n",
    "]\n",
    "\n",
    "# Execute Git commands\n",
    "for command in commands:\n",
    "    try:\n",
    "        subprocess.run(command, check=True, shell=True)\n",
    "        print(f\"Successfully executed: {command}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred while executing: {command}\\nError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random example from the validation dataset.\n",
    "example = X_val[np.random.choice(range(len(X_val)), size=1)[0]]\n",
    "\n",
    "# Pick the first/last ten frames from the example.\n",
    "frames = example[:10, ...]\n",
    "original_frames = example[10:, ...]\n",
    "\n",
    "# Predict a new set of 10 frames.\n",
    "for _ in range(10):\n",
    "    # Extract the model's prediction and post-process it.\n",
    "    new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "    new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "    predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "\n",
    "    # Extend the set of prediction frames.\n",
    "    frames = np.concatenate((frames, predicted_frame), axis=0)\n",
    "\n",
    "# Construct a figure for the original and new frames.\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 14))\n",
    "\n",
    "# Plot the original frames.\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "    ax.imshow(np.squeeze(original_frames[idx]), cmap=radar_cmap, norm=norm)\n",
    "    ax.set_title(f\"Frame {idx + 11}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Plot the new frames.\n",
    "new_frames = frames[10:, ...]\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "    ax.imshow(np.squeeze(new_frames[idx]), cmap=radar_cmap, norm=norm)\n",
    "    ax.set_title(f\"Frame {idx + 11}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Display the figure.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few random examples from the dataset.\n",
    "examples = X_test[np.random.choice(range(len(X_test)), size=1)]\n",
    "\n",
    "\n",
    "# Iterate over the examples and predict the frames.\n",
    "predicted_videos = []\n",
    "for example in examples:\n",
    "    # Pick the first/last ten frames from the example.\n",
    "    frames = example[:10, ...]\n",
    "    original_frames = example[10:, ...]\n",
    "    new_predictions = np.zeros(shape=(10, *frames[0].shape))\n",
    "\n",
    "    # Predict a new set of 10 frames.\n",
    "    for i in range(10):\n",
    "        # Extract the model's prediction and post-process it.\n",
    "        frames = example[: 10 + i + 1, ...]\n",
    "        new_prediction = model.predict(np.expand_dims(frames, axis=0))\n",
    "        new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "        predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "\n",
    "        # Extend the set of prediction frames.\n",
    "        new_predictions[i] = predicted_frame\n",
    "\n",
    "    # Create and save GIFs for each of the ground truth/prediction images.\n",
    "    for frame_set in [original_frames, new_predictions]:\n",
    "        # Construct a GIF from the selected video frames.\n",
    "        current_frames = np.squeeze(frame_set)\n",
    "        current_frames = current_frames[..., np.newaxis] * np.ones(3)\n",
    "        current_frames = (current_frames * 255).astype(np.uint8)\n",
    "        current_frames = list(current_frames)\n",
    "\n",
    "        # Construct a GIF from the frames.\n",
    "        with io.BytesIO() as gif:\n",
    "            imageio.mimsave(gif, current_frames, \"GIF\", duration=200)\n",
    "            predicted_videos.append(gif.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the videos.\n",
    "print(\" Truth\\tPrediction\")\n",
    "for i in range(0, len(predicted_videos), 2):\n",
    "    # Construct and display an `HBox` with the ground truth and prediction.\n",
    "    box = HBox(\n",
    "        [\n",
    "            widgets.Image(value=predicted_videos[i]),\n",
    "            widgets.Image(value=predicted_videos[i + 1]),\n",
    "        ]\n",
    "    )\n",
    "    display(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "radarenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
